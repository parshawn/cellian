{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd70fd55",
   "metadata": {},
   "source": [
    "# STATE Transition Model Training on SCP1064\n",
    "\n",
    "This notebook adapts the official STATE training notebook  for the custom Perturb-CITE-seq dataset (SCP1064).\n",
    "\n",
    "The workflow is as follows:\n",
    "1.  **Setup**: Define file paths and import libraries.\n",
    "2.  **Data Preprocessing**:\n",
    "    * Load RNA expression and metadata from your CSVs.\n",
    "    * Create a single `AnnData` object.\n",
    "    * Apply your custom metadata processing (filling \"CTRL\", creating 'perturbation' column).\n",
    "    * Apply the standard preprocessing from the reference: normalize to 10k counts and log-transform .\n",
    "    * Calculate and store 2000 Highly Variable Genes (HVGs).\n",
    "    * Save the final processed data as a `.h5ad` file.\n",
    "3.  **Create TOML Config**:\n",
    "    * Define a train/val/test split by holding out a subset of perturbations from one cellular context, similar to the reference's 'few-shot' setup[cite: 252, 281].\n",
    "    * This split is saved to a `.toml` file.\n",
    "4.  **Install & Train**:\n",
    "    * Change to your local `state` repo directory.\n",
    "    * Install dependencies using `uv`.\n",
    "    * Run the `state tx train` command, pointing to our new data and TOML config.\n",
    "5.  **Predict**:\n",
    "    * Run inference and evaluation on the holdout test set[cite: 449]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ca525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import toml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- User-defined Paths ---\n",
    "# Directory for your data\n",
    "data_dir = \"/home/nebius/cellian/data/perturb-cite-seq/SCP1064\"\n",
    "\n",
    "# Input files\n",
    "meta_path = f\"{data_dir}/metadata/RNA_metadata.csv\"\n",
    "rna_csv = f\"{data_dir}/expression/RNA_expression_subset1a.csv\"\n",
    "protein_csv = f\"{data_dir}/expression/Protein_expression.csv\" # Note: The reference ST model uses RNA profiles [cite: 14]\n",
    "\n",
    "# Path to your local clone of the STATE repo\n",
    "state_repo_dir = \"/home/nebius/ST-Tahoe\"\n",
    "\n",
    "# Output files\n",
    "processed_data_dir = f\"{data_dir}/processed\"\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "output_adata_path = f\"{processed_data_dir}/scp1064_processed.h5ad\"\n",
    "output_toml_path = f\"{state_repo_dir}/scp1064_split.toml\" # Save TOML config in the repo dir for easy access\n",
    "\n",
    "CELL_TYPE_COLUMN = 'condition' \n",
    "PERTURBATION_COLUMN = 'perturbation'\n",
    "CONTROL_LABEL = 'CTRL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7c408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /home/nebius/cellian/data/perturb-cite-seq/SCP1064/metadata/RNA_metadata.csv...\n",
      "Loading RNA expression from /home/nebius/cellian/data/perturb-cite-seq/SCP1064/expression/RNA_expression_subset1a.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2725206/1791306932.py:13: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_df = pd.read_csv(meta_path, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning data...\n",
      "Saving raw AnnData to /home/nebius/cellian/data/perturb-cite-seq/SCP1064/processed/scp1064_raw.h5ad...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run this code *once* to create your raw input file\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "# --- Your file paths ---\n",
    "data_dir = \"/home/nebius/cellian/data/perturb-cite-seq/SCP1064\"\n",
    "meta_path = f\"{data_dir}/metadata/RNA_metadata.csv\"\n",
    "rna_csv = f\"{data_dir}/expression/RNA_expression_subset1a.csv\"\n",
    "output_raw_adata = f\"{data_dir}/processed/scp1064_raw.h5ad\"\n",
    "\n",
    "# --- Load and align ---\n",
    "print(f\"Loading metadata from {meta_path}...\")\n",
    "meta_df = pd.read_csv(meta_path, index_col=0)\n",
    "\n",
    "print(f\"Loading RNA expression from {rna_csv}...\")\n",
    "rna_df = pd.read_csv(rna_csv, index_col=0)\n",
    "rna_df_t = rna_df.T # Transpose to (cells x genes)\n",
    "\n",
    "print(\"Aligning data...\")\n",
    "common_cells = rna_df_t.index.intersection(meta_df.index)\n",
    "rna_df_t = rna_df_t.loc[common_cells]\n",
    "meta_df = meta_df.loc[common_cells]\n",
    "\n",
    "# --- Create AnnData object ---\n",
    "adata = ad.AnnData(X=rna_df_t.values, obs=meta_df)\n",
    "adata.var_names = rna_df.index.tolist()\n",
    "\n",
    "# --- Apply your custom column logic ---\n",
    "adata.obs['sgRNA'] = adata.obs['sgRNA'].fillna(\"CTRL\")\n",
    "adata.obs['perturbation'] = adata.obs['sgRNA'].str.replace(r\"(_\\d+)$\", \"\", regex=True)\n",
    "\n",
    "# --- Save the RAW file ---\n",
    "print(f\"Saving raw AnnData to {output_raw_adata}...\")\n",
    "adata.write(output_raw_adata)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe57f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /home/nebius/cellian/data/perturb-cite-seq/SCP1064/metadata/RNA_metadata.csv...\n",
      "Loading RNA expression from /home/nebius/cellian/data/perturb-cite-seq/SCP1064/expression/RNA_expression_subset1a.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2725206/3906582621.py:2: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_df = pd.read_csv(meta_path, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposing RNA matrix to (cells x genes)...\n",
      "Aligning metadata and expression data...\n",
      "Found 27291 common cells.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading metadata from {meta_path}...\")\n",
    "meta_df = pd.read_csv(meta_path, index_col=0)\n",
    "\n",
    "print(f\"Loading RNA expression from {rna_csv}...\")\n",
    "# Genes as index, cells as columns\n",
    "rna_df = pd.read_csv(rna_csv, index_col=0)\n",
    "\n",
    "# Transpose RNA data: AnnData expects (observations x variables), i.e., (cells x genes)\n",
    "print(\"Transposing RNA matrix to (cells x genes)...\")\n",
    "rna_df_t = rna_df.T\n",
    "\n",
    "# Align metadata and expression data\n",
    "print(\"Aligning metadata and expression data...\")\n",
    "common_cells = rna_df_t.index.intersection(meta_df.index)\n",
    "if len(common_cells) == 0:\n",
    "    raise ValueError(\"No common cells found between RNA expression and metadata. Check cell identifiers.\")\n",
    "\n",
    "print(f\"Found {len(common_cells)} common cells.\")\n",
    "rna_df_t = rna_df_t.loc[common_cells]\n",
    "meta_df = meta_df.loc[common_cells]\n",
    "\n",
    "# Create AnnData object\n",
    "adata = ad.AnnData(X=rna_df_t.values, obs=meta_df)\n",
    "adata.var_names = rna_df.index.tolist()\n",
    "del rna_df, rna_df_t, meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8f1c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying custom metadata processing...\n",
      "Unique perturbations created. Example: ['HLA-B' 'CTRL' 'IFNGR1' 'CDKN1A' 'EMP1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying custom metadata processing...\")\n",
    "# 1. Fill NA in 'sgRNA' with 'CTRL'\n",
    "adata.obs['sgRNA'] = adata.obs['sgRNA'].fillna(CONTROL_LABEL)\n",
    "# 2. Create 'perturbation' column by stripping sgRNA number\n",
    "adata.obs[PERTURBATION_COLUMN] = adata.obs['sgRNA'].str.replace(r\"(_\\d+)$\", \"\", regex=True)\n",
    "\n",
    "print(f\"Unique perturbations created. Example: {adata.obs[PERTURBATION_COLUMN].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509c5c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library_preparation_protocol</th>\n",
       "      <th>condition</th>\n",
       "      <th>MOI</th>\n",
       "      <th>sgRNA</th>\n",
       "      <th>UMI_count</th>\n",
       "      <th>perturbation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CELL_1</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>HLA-B_2</td>\n",
       "      <td>10832.0</td>\n",
       "      <td>HLA-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_2</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10731.0</td>\n",
       "      <td>CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_3</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>HLA-B_2</td>\n",
       "      <td>28821.0</td>\n",
       "      <td>HLA-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_4</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>15322.0</td>\n",
       "      <td>CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_5</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10314.0</td>\n",
       "      <td>CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_27287</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>SLC25A13_3</td>\n",
       "      <td>27548.0</td>\n",
       "      <td>SLC25A13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_27288</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>ONE_NON-GENE_SITE_658</td>\n",
       "      <td>18509.0</td>\n",
       "      <td>ONE_NON-GENE_SITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_27289</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>15669.0</td>\n",
       "      <td>CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_27290</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>20478.0</td>\n",
       "      <td>CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_27291</th>\n",
       "      <td>10X 3' v3 sequencing</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>GSEC_2</td>\n",
       "      <td>905.0</td>\n",
       "      <td>GSEC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27291 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           library_preparation_protocol condition MOI                  sgRNA  \\\n",
       "CELL_1             10X 3' v3 sequencing   Control   1                HLA-B_2   \n",
       "CELL_2             10X 3' v3 sequencing   Control   2                   CTRL   \n",
       "CELL_3             10X 3' v3 sequencing   Control   1                HLA-B_2   \n",
       "CELL_4             10X 3' v3 sequencing   Control   2                   CTRL   \n",
       "CELL_5             10X 3' v3 sequencing   Control   0                   CTRL   \n",
       "...                                 ...       ...  ..                    ...   \n",
       "CELL_27287         10X 3' v3 sequencing   Control   1             SLC25A13_3   \n",
       "CELL_27288         10X 3' v3 sequencing   Control   1  ONE_NON-GENE_SITE_658   \n",
       "CELL_27289         10X 3' v3 sequencing   Control   2                   CTRL   \n",
       "CELL_27290         10X 3' v3 sequencing   Control   2                   CTRL   \n",
       "CELL_27291         10X 3' v3 sequencing   Control   1                 GSEC_2   \n",
       "\n",
       "           UMI_count       perturbation  \n",
       "CELL_1       10832.0              HLA-B  \n",
       "CELL_2       10731.0               CTRL  \n",
       "CELL_3       28821.0              HLA-B  \n",
       "CELL_4       15322.0               CTRL  \n",
       "CELL_5       10314.0               CTRL  \n",
       "...              ...                ...  \n",
       "CELL_27287   27548.0           SLC25A13  \n",
       "CELL_27288   18509.0  ONE_NON-GENE_SITE  \n",
       "CELL_27289   15669.0               CTRL  \n",
       "CELL_27290   20478.0               CTRL  \n",
       "CELL_27291     905.0               GSEC  \n",
       "\n",
       "[27291 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e730a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying standard preprocessing (Normalize total, log1p)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 2000 Highly Variable Genes (HVGs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebius/miniconda/envs/new_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:88: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  return fn(*args_all, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing HVG array in .obsm['X_hvg']...\n",
      "Saving processed AnnData object to /home/nebius/cellian/data/perturb-cite-seq/SCP1064/processed/scp1064_processed.h5ad...\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying standard preprocessing (Normalize total, log1p)...\")\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# --- Compute and Store Highly Variable Genes (HVGs) ---\n",
    "# The reference notebook computes 2000 HVGs.\n",
    "print(\"Calculating 2000 Highly Variable Genes (HVGs)...\")\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat_v3')\n",
    "\n",
    "# Store HVG data in .obsm as a dense array, just like the reference [cite: 228-230]\n",
    "print(\"Storing HVG array in .obsm['X_hvg']...\")\n",
    "hvg_data = adata.X[:, adata.var['highly_variable']]\n",
    "if sparse.issparse(hvg_data):\n",
    "    hvg_data = hvg_data.toarray()\n",
    "adata.obsm['X_hvg'] = hvg_data\n",
    "print(f\"Saving processed AnnData object to {output_adata_path}...\")\n",
    "adata.write(output_adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 cellular contexts: ['Control']\n",
      "Selected context 'Control' to create val/test splits from.\n",
      "Found 250 perturbations in 'Control'.\n",
      "Split: 125 validation perts, 125 test perts.\n",
      "Saving TOML config to /home/nebius/ST-Tahoe/scp1064_split.toml...\n",
      "\n",
      "TOML config generation complete.\n",
      "--- Config Preview (first 5 perts) ---\n",
      "[fewshot.scp1064_dataset.Control]\n",
      "val = ['PFN1', 'SMAD4', 'APOD', 'CTSO', 'CD44']...\n",
      "test = ['SHMT2', 'SPESP1', 'NEAT1', 'CCND1', 'P2RX4']...\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_contexts = adata.obs[CELL_TYPE_COLUMN].unique().tolist()\n",
    "if not all_contexts:\n",
    "    raise ValueError(f\"No contexts found in column '{CELL_TYPE_COLUMN}'. Please check the column name.\")\n",
    "\n",
    "print(f\"Found {len(all_contexts)} cellular contexts: {all_contexts}\")\n",
    "\n",
    "# --- Define the Split ---\n",
    "# We pick ONE context to split for validation and testing\n",
    "# All other contexts will be used entirely for training.\n",
    "context_to_split = all_contexts[0]\n",
    "print(f\"Selected context '{context_to_split}' to create val/test splits from.\")\n",
    "\n",
    "# Get all perturbations present in this context, excluding the control\n",
    "perts_in_context = adata[adata.obs[CELL_TYPE_COLUMN] == context_to_split].obs[PERTURBATION_COLUMN].unique()\n",
    "perts_in_context = [p for p in perts_in_context if p != CONTROL_LABEL]\n",
    "print(f\"Found {len(perts_in_context)} perturbations in '{context_to_split}'.\")\n",
    "\n",
    "# Split these perturbations into validation and test sets (e.g., 50/50 split)\n",
    "val_perts, test_perts = train_test_split(perts_in_context, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Split: {len(val_perts)} validation perts, {len(test_perts)} test perts.\")\n",
    "\n",
    "# --- Build the TOML Config Dictionary ---\n",
    "# This structure follows the reference notebook [cite: 265-281]\n",
    "\n",
    "DATASET_NAME = \"scp1064_dataset\" # An internal name for this dataset\n",
    "\n",
    "config = {\n",
    "    # Map the dataset name to the *directory* containing the .h5ad file\n",
    "    \"datasets\": {\n",
    "        DATASET_NAME: processed_data_dir\n",
    "    },\n",
    "    \n",
    "    # Specify which datasets to use for training\n",
    "    \"training\": {\n",
    "        DATASET_NAME: \"train\"\n",
    "    },\n",
    "    \n",
    "    # Define zero-shot holdouts (none in this setup)\n",
    "    \"zeroshot\": {},\n",
    "    \n",
    "    # Define few-shot holdouts\n",
    "    \"fewshot\": {\n",
    "        # The key is \"dataset_name.context_name\"\n",
    "        f\"{DATASET_NAME}.{context_to_split}\": {\n",
    "            \"val\": list(val_perts),\n",
    "            \"test\": list(test_perts)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Save the TOML File ---\n",
    "print(f\"Saving TOML config to {output_toml_path}...\")\n",
    "with open(output_toml_path, 'w') as f:\n",
    "    toml.dump(config, f)\n",
    "\n",
    "print(\"\\nTOML config generation complete.\")\n",
    "print(f\"--- Config Preview (first 5 perts) ---\")\n",
    "print(f\"[fewshot.{DATASET_NAME}.{context_to_split}]\")\n",
    "print(f\"val = {list(val_perts)[:5]}...\")\n",
    "print(f\"test = {list(test_perts)[:5]}...\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36423c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nebius/ST-Tahoe\n"
     ]
    }
   ],
   "source": [
    "%cd {state_repo_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d625c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: No `pyproject.toml` found in current directory or any parent directory\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add \"cell-load>=0.7.11\" toml pandas scikit-learn scanpy anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d8c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/nebius/.local/bin/state\"\u001b[0m, line \u001b[35m10\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/state/__main__.py\"\u001b[0m, line \u001b[35m119\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    cfg = load_hydra_config(\"tx\", args.hydra_overrides)\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/state/__main__.py\"\u001b[0m, line \u001b[35m45\u001b[0m, in \u001b[35mload_hydra_config\u001b[0m\n",
      "    cfg = compose(config_name=\"config\", overrides=overrides)\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/compose.py\"\u001b[0m, line \u001b[35m38\u001b[0m, in \u001b[35mcompose\u001b[0m\n",
      "    cfg = gh.hydra.compose_config(\n",
      "        config_name=config_name,\n",
      "    ...<3 lines>...\n",
      "        with_log_configuration=False,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/hydra.py\"\u001b[0m, line \u001b[35m594\u001b[0m, in \u001b[35mcompose_config\u001b[0m\n",
      "    cfg = self.config_loader.load_configuration(\n",
      "        config_name=config_name,\n",
      "    ...<3 lines>...\n",
      "        validate_sweep_overrides=validate_sweep_overrides,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/config_loader_impl.py\"\u001b[0m, line \u001b[35m142\u001b[0m, in \u001b[35mload_configuration\u001b[0m\n",
      "    return \u001b[31mself._load_configuration_impl\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mconfig_name=config_name,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<3 lines>...\n",
      "        \u001b[1;31mvalidate_sweep_overrides=validate_sweep_overrides,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/config_loader_impl.py\"\u001b[0m, line \u001b[35m253\u001b[0m, in \u001b[35m_load_configuration_impl\u001b[0m\n",
      "    defaults_list = create_defaults_list(\n",
      "        repo=caching_repo,\n",
      "    ...<3 lines>...\n",
      "        skip_missing=run_mode == RunMode.MULTIRUN,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m745\u001b[0m, in \u001b[35mcreate_defaults_list\u001b[0m\n",
      "    defaults, tree = \u001b[31m_create_defaults_list\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                     \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mrepo,\u001b[0m\n",
      "        \u001b[1;31m^^^^^\u001b[0m\n",
      "    ...<3 lines>...\n",
      "        \u001b[1;31mskip_missing=skip_missing,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m715\u001b[0m, in \u001b[35m_create_defaults_list\u001b[0m\n",
      "    defaults_tree = _create_defaults_tree(\n",
      "        repo=repo,\n",
      "    ...<4 lines>...\n",
      "        skip_missing=skip_missing,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m356\u001b[0m, in \u001b[35m_create_defaults_tree\u001b[0m\n",
      "    ret = _create_defaults_tree_impl(\n",
      "        repo=repo,\n",
      "    ...<4 lines>...\n",
      "        overrides=overrides,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m457\u001b[0m, in \u001b[35m_create_defaults_tree_impl\u001b[0m\n",
      "    return _expand_virtual_root(repo, root, overrides, skip_missing)\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m280\u001b[0m, in \u001b[35m_expand_virtual_root\u001b[0m\n",
      "    subtree = _create_defaults_tree_impl(\n",
      "        repo=repo,\n",
      "    ...<4 lines>...\n",
      "        overrides=overrides,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m573\u001b[0m, in \u001b[35m_create_defaults_tree_impl\u001b[0m\n",
      "    \u001b[31madd_child\u001b[0m\u001b[1;31m(children, new_root)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m520\u001b[0m, in \u001b[35madd_child\u001b[0m\n",
      "    subtree_ = _create_defaults_tree_impl(\n",
      "        repo=repo,\n",
      "    ...<4 lines>...\n",
      "        overrides=overrides,\n",
      "    )\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m488\u001b[0m, in \u001b[35m_create_defaults_tree_impl\u001b[0m\n",
      "    \u001b[31mconfig_not_found_error\u001b[0m\u001b[1;31m(repo=repo, tree=root)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/hydra/_internal/defaults_list.py\"\u001b[0m, line \u001b[35m799\u001b[0m, in \u001b[35mconfig_not_found_error\u001b[0m\n",
      "    raise MissingConfigException(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "\u001b[1;35mhydra.errors.MissingConfigException\u001b[0m: \u001b[35mIn 'config': Could not find 'wandb/default'\n",
      "\n",
      "Config search path:\n",
      "\tprovider=hydra, path=pkg://hydra.conf\n",
      "\tprovider=main, path=file:///home/nebius/.local/share/uv/tools/arc-state/lib/python3.13/site-packages/state/configs\n",
      "\tprovider=schema, path=structured://\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv run state tx train \\\n",
    "    data.kwargs.toml_config_path=\"{output_toml_path}\" \\\n",
    "    data.kwargs.num_workers=4 \\\n",
    "    data.kwargs.output_space=\"gene\" \\\n",
    "    data.kwargs.batch_col=\"gem_group\" \\\n",
    "    data.kwargs.pert_col=\"{PERTURBATION_COLUMN}\" \\\n",
    "    data.kwargs.cell_type_key=\"{CELL_TYPE_COLUMN}\" \\\n",
    "    data.kwargs.control_pert=\"{CONTROL_LABEL}\" \\\n",
    "    training.max_steps=80000 \\\n",
    "    training.ckpt_every_n_steps=2000 \\\n",
    "    training.batch_size=64 \\\n",
    "    training.lr=1e-3 \\\n",
    "    model.kwargs.cell_set_len=64 \\\n",
    "    model.kwargs.hidden_dim=128 \\\n",
    "    model.kwargs.batch_encoder=True \\\n",
    "    model=state \\\n",
    "    wandb.entity=\"arcinstitute\" \\\n",
    "    wandb.tags=\"[scp1064_run]\" \\\n",
    "    output_dir=\"test_scp1064\" \\\n",
    "    name=\"scp1064_holdout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run state tx predict \\\n",
    "    --output_dir \"test_scp1064/scp1064_holdout\" \\\n",
    "    --checkpoint \"last.ckpt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
